---
layout: archive
title: "CV"
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

You can download a PDF copy of my CV [here]({{ base_path }}/files/Hanyu_CV.pdf).

<iframe src="{{ base_path }}/files/Hanyu_CV.pdf" width="100%" height="800" style="border: none;"></iframe>

Education
======
* B.S. in Mathematics, University of Science and Technology of China (USTC), 2020-2024
* Ph.D. in Informatics, Pennsylvania State University, 2024-Present
  * Advisor: Dr. [Jinghui Chen](https://jinghuichen.github.io/)

Research Experience
======
* Aug. 2024 -- Present: PhD Student
  * The Pennsylvania State University
  * Advisor: Dr. [Jinghui Chen](https://jinghuichen.github.io/)

* Jul. 2023 -- Jun. 2024: Research Assistant
  * The University of Hong Kong (HKU)
  * Project: Empirical Understanding of Generalizability in Diffusion Models
  * Supervisor: Dr. [Difan Zou](https://difanzou.github.io/)

* Jan. 2023 -- Dec. 2023: Undergraduate Student Research Program
  * University of Science and Technology of China (USTC)
  * Project: On Mitigating Memorization in Diffusion Models
  * Supervisor: Dr. [Jingrun Chen](https://faculty.ustc.edu.cn/chenjingrun/)

Preprints
======
* **PreFlect: From Retrospective to Prospective Reflection in Large Language Model Agents** [[Paper]](https://arxiv.org/pdf/2602.07187)
  <br>Hanyu Wang, Yuanpu Cao, Lu Lin, Jinghui Chen

Publications
======
* **TruthFlow: Truthful LLM Generation via Representation Flow Correction** [[Paper]](https://arxiv.org/abs/2502.04556)
  <br>Hanyu Wang, Bochuan Cao, Yuanpu Cao, Jinghui Chen
  <br>*Proceedings of the 42nd International Conference on Machine Learning (ICML 2025)*

* **On the Discrepancy and Connection between Memorization and Generation in Diffusion Models** [[Paper]](https://openreview.net/pdf?id=ZqG5lo18tq)
  <br>Hanyu Wang, Yujin Han, Difan Zou
  <br>*ICML 2024 Workshop on Foundation Models in the Wild*
