---
permalink: /
title: "Welcome to Hanyu Wang's Homepage!"
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

I am Hanyu Wang, a second-year PhD student at Penn State University, fortunate to be advised by [Prof. Jinghui Chen](https://jinghuichen.github.io/). Previously, I received my Bachelor of Science degree from the Department of Mathematics at University of Science and Technology of China (USTC) in June 2024.

My research lies at the intersection of Natural Language Processing and Trustworthy AI. I am broadly interested in a range of topics aimed at making AI systems more capable and reliable, including:

* Understanding and mitigating hallucinations in LLMs.
* Enhancing the multi-step reasoning abilities of language models.
* Building advanced agentic systems capable of reflection.

<div style="background-color: #e8f4fd; border-left: 4px solid #1a73e8; padding: 12px 16px; margin: 16px 0 24px 0; border-radius: 4px;">
  <strong>I am actively looking for a 2026 summer research internship!</strong> If you are interested, please feel free to reach out via <a href="mailto:hbw5365@psu.edu">email</a>.
</div>

News
======

* [2025/05] Our paper, "[TruthFlow: Truthful LLM Generation via Representation Flow Correction](https://arxiv.org/abs/2502.04556)", was accepted to **ICML 2025**!
* [2024/07] Our paper, "[On the Discrepancy and Connection between Memorization and Generation in Diffusion Models](https://openreview.net/pdf?id=ZqG5lo18tq)", was accepted to **ICML 2024 Workshop on Foundation Models in the Wild**.

Selected Publications
======

* **PreFlect: From Retrospective to Prospective Reflection in Large Language Model Agents** [[Paper]](https://arxiv.org/pdf/2602.07187)
  <br>Hanyu Wang, Yuanpu Cao, Lu Lin, Jinghui Chen
  <br>*Preprint / Under Review*

* **TruthFlow: Truthful LLM Generation via Representation Flow Correction** [[Paper]](https://arxiv.org/abs/2502.04556)
  <br>Hanyu Wang, Bochuan Cao, Yuanpu Cao, Jinghui Chen
  <br>*Proceedings of the 42nd International Conference on Machine Learning (ICML 2025)*

* **On the Discrepancy and Connection between Memorization and Generation in Diffusion Models** [[Paper]](https://openreview.net/pdf?id=ZqG5lo18tq)
  <br>Hanyu Wang, Yujin Han, Difan Zou
  <br>*ICML 2024 Workshop on Foundation Models in the Wild*

Contact
=======
Email: hbw5365 at psu dot edu
